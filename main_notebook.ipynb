{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install and import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n3IlwsTHBFT"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai langchain-openai langchain-community unstructured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_WdC6qdXomd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import CSVLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.indexes import VectorstoreIndexCreator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Enter your OpenAI API Key below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNZ2vq2WHB8J",
        "outputId": "545e9211-d636-46cd-f2b9-49fe1f3b3d1c"
      },
      "outputs": [],
      "source": [
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prompt Template for efficient outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlkWopY4Gd8Q"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer or the question is not related to the provided context, just say that you don't know, don't try to make up an answer.\n",
        "Use 10 sentences maximum, add bullet points where applicable and keep the answer as reasonable as possible.\n",
        "Get idea from below Examples:\n",
        "Examples:\n",
        "\"question\": What does the study \"Disrupting Industries With Blockchain: The Industry, Venture Capital Funding, and Regional Distribution of Blockchain Ventures\" investigate and what are its key findings?\",\n",
        "\"answer\": \"The study investigates the emerging landscape of blockchain business applications by analyzing their presence across industries, venture capital funding, and regional distribution. It uses data from four venture databases to explore the diffusion of blockchain technology. Key findings include:\n",
        "1- Blockchain startups are present across all industry segments, with the most significant representation in the Finance & Insurance and Information & Communication industries.\n",
        "2- These industries are also the primary recipients of venture capital funding, though blockchain startups exist in various sectors.\n",
        "3- The regional distribution analysis identifies the US and UK as leading geographical clusters for blockchain ventures.\"\n",
        "\"question\": \"How to play snooker?\"\n",
        "\"answer\": \"I don't know the answer. The question is not relevant to the provided context.\"\n",
        "\"question\": \"Who is Nicolas Poran?\"\n",
        "\"answer\": \"I don't know the answer. The question is not relevant to the provided context.\"\n",
        "\n",
        "You will know answer the questions from the provided context. If the questions is not relevant, just say you don't know the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CSV Files path and loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "csv_file_path = 'Enter Your csv folder path here'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGReiJLoNytN"
      },
      "outputs": [],
      "source": [
        "loader = DirectoryLoader(csv_file_path, glob=\"**/*.csv\", loader_cls=CSVLoader, loader_kwargs={'encoding': 'utf-8'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Index Creation and Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sDMyC1JN6zz"
      },
      "outputs": [],
      "source": [
        "embedding_model = OpenAIEmbeddings()\n",
        "index_creator = VectorstoreIndexCreator(embedding=embedding_model)\n",
        "docsearch = index_creator.from_loaders([loader])\n",
        "retriever = docsearch.vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={'k': 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Integration and Chain Type Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHXz6hq2QOlC"
      },
      "outputs": [],
      "source": [
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
        "chain_type_kwargs = {\"prompt\": QA_CHAIN_PROMPT}\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60x-UYsNQYWq"
      },
      "outputs": [],
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True, chain_type_kwargs=chain_type_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Queries Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9qwLugLiaosj",
        "outputId": "49d9b8a3-ad23-475c-b95b-a4037a5cba5e"
      },
      "outputs": [],
      "source": [
        "question = \"How to play snooker?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaTBWRaqjTeV",
        "outputId": "15140706-b8e1-4e73-9234-4af3f134425c"
      },
      "outputs": [],
      "source": [
        "user_question = \"Is Ernst & Young Global Limited a service provider to clients?\"\n",
        "result = qa_chain({\"query\": user_question})\n",
        "print(\"Question:\", user_question, \"\\nAnswer: \", result[\"result\"], \"\\nSource:\\n\", [document.metadata for document in result[\"source_documents\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Suo6vMvkKiOH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
